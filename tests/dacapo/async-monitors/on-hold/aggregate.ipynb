{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"/home/alejandro/jRAPL/tests/dacapo/async-monitors/results/jolteon-results\"\n",
    "os.chdir(data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' https://math.stackexchange.com/questions/1547141/aggregating-standard-deviation-to-a-summary-point?fbclid=IwAR3GpT8cNoNbMHntA1dKhWKHGXvBj2W-t7NQU29qoqtsg37uZKZgkeDM-aE <-- formulas for aggr_mean and aggr_stdev '''\n",
    "\n",
    "def aggr_mean(sample_sizes, averages):\n",
    "    assert len(sample_sizes) == len(averages)\n",
    "    return sum([ (sample_sizes[i]*averages[i]) for i in range(len(sample_sizes)) ]) / sum(sample_sizes)\n",
    "\n",
    "def aggr_stdev(sample_sizes, stdevs):\n",
    "    assert len(sample_sizes) == len(stdevs)\n",
    "    return math.sqrt(sum([ (sample_sizes[i]*(stdevs[i]**2)) for i in range(len(sample_sizes)) ]) / sum (sample_sizes))\n",
    "\n",
    "def aggregate_memory_stats(memory_data):\n",
    "\n",
    "    mem_stats = {}\n",
    "    mem_stats['avg']   = aggr_mean([dat['num_samples'] for dat in memory_data], [dat['avg'] for dat in memory_data])\n",
    "    mem_stats['stdev'] = aggr_stdev([dat['num_samples'] for dat in memory_data], [dat['avg'] for dat in memory_data])\n",
    "    mem_stats['global_min'] = min( [ dat['min'] for dat in memory_data] )\n",
    "    mem_stats['global_max'] = max( [ dat['max'] for dat in memory_data] )\n",
    "    mem_stats['avg_min'] = statistics.mean( [ dat['min'] for dat in memory_data ] )\n",
    "    mem_stats['avg_max'] = statistics.mean( [ dat['max'] for dat in memory_data ] )\n",
    "    return mem_stats\n",
    "\n",
    "\"\"\"\n",
    "  Assumes 'data' is an array of structurally identical JSON object, where\n",
    "  all of the leaf objects have keys ['avg','num_samples','stdev']. Recursively\n",
    "  descends and then aggregates each of these three fields with the appropriate\n",
    "  aggregation function.\n",
    "\"\"\"\n",
    "def general_aggregate(data):\n",
    "\tres = {}\n",
    "\tif sorted(list(data[0].keys())) != sorted(['avg','num_samples','stdev']):\n",
    "\t\tfor k in data[0].keys():\n",
    "\t\t\tres[k] = general_aggregate( [ d[k] for d in data ] )\n",
    "\telse: # at the leaves\n",
    "\t\tsample_sizes = [ d['num_samples'] for d in data ]\n",
    "\t\tres['avg'] = aggr_mean( sample_sizes,  [d['avg'] for d in data ] )\n",
    "\t\tres['stdev'] = aggr_stdev( sample_sizes, [ d['stdev'] for d in data ] )\n",
    "\t\tres['num_samples'] = statistics.mean( [ d['num_samples'] for d in data ] )\n",
    "\n",
    "\treturn res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " >> wrote to outfile: jython_c-linklist.aggregate-stats.json\n >> wrote to outfile: jython_c-dynamicarray.aggregate-stats.json\n >> wrote to outfile: jython_java.aggregate-stats.json\n >> wrote to outfile: sunflow_c-linklist.aggregate-stats.json\n >> wrote to outfile: sunflow_c-dynamicarray.aggregate-stats.json\n >> wrote to outfile: sunflow_java.aggregate-stats.json\n >> wrote to outfile: batik_c-linklist.aggregate-stats.json\n >> wrote to outfile: batik_c-dynamicarray.aggregate-stats.json\n >> wrote to outfile: batik_java.aggregate-stats.json\n >> wrote to outfile: h2o_c-linklist.aggregate-stats.json\n >> wrote to outfile: h2o_c-dynamicarray.aggregate-stats.json\n >> wrote to outfile: h2o_java.aggregate-stats.json\n >> wrote to outfile: fop_c-linklist.aggregate-stats.json\n >> wrote to outfile: fop_c-dynamicarray.aggregate-stats.json\n >> wrote to outfile: fop_java.aggregate-stats.json\n >> wrote to outfile: tradebeans_c-linklist.aggregate-stats.json\n >> wrote to outfile: tradebeans_c-dynamicarray.aggregate-stats.json\n >> wrote to outfile: tradebeans_java.aggregate-stats.json\n >> wrote to outfile: lusearch_c-linklist.aggregate-stats.json\n >> wrote to outfile: lusearch_c-dynamicarray.aggregate-stats.json\n >> wrote to outfile: lusearch_java.aggregate-stats.json\n >> wrote to outfile: luindex_c-linklist.aggregate-stats.json\n >> wrote to outfile: luindex_c-dynamicarray.aggregate-stats.json\n >> wrote to outfile: luindex_java.aggregate-stats.json\n >> wrote to outfile: jme_c-linklist.aggregate-stats.json\n >> wrote to outfile: jme_c-dynamicarray.aggregate-stats.json\n >> wrote to outfile: jme_java.aggregate-stats.json\n >> wrote to outfile: eclipse_c-linklist.aggregate-stats.json\n >> wrote to outfile: eclipse_c-dynamicarray.aggregate-stats.json\n >> wrote to outfile: eclipse_java.aggregate-stats.json\n >> wrote to outfile: biojava_c-linklist.aggregate-stats.json\n >> wrote to outfile: biojava_c-dynamicarray.aggregate-stats.json\n >> wrote to outfile: biojava_java.aggregate-stats.json\n >> wrote to outfile: tradesoap_c-linklist.aggregate-stats.json\n >> wrote to outfile: tradesoap_c-dynamicarray.aggregate-stats.json\n >> wrote to outfile: tradesoap_java.aggregate-stats.json\n >> wrote to outfile: cassandra_c-linklist.aggregate-stats.json\n >> wrote to outfile: cassandra_c-dynamicarray.aggregate-stats.json\n >> wrote to outfile: cassandra_java.aggregate-stats.json\n >> wrote to outfile: pmd_c-linklist.aggregate-stats.json\n >> wrote to outfile: pmd_c-dynamicarray.aggregate-stats.json\n >> wrote to outfile: pmd_java.aggregate-stats.json\n >> wrote to outfile: tomcat_c-linklist.aggregate-stats.json\n >> wrote to outfile: tomcat_c-dynamicarray.aggregate-stats.json\n >> wrote to outfile: tomcat_java.aggregate-stats.json\n >> wrote to outfile: zxing_c-linklist.aggregate-stats.json\n >> wrote to outfile: zxing_c-dynamicarray.aggregate-stats.json\n >> wrote to outfile: zxing_java.aggregate-stats.json\n >> wrote to outfile: h2_c-linklist.aggregate-stats.json\n >> wrote to outfile: h2_c-dynamicarray.aggregate-stats.json\n >> wrote to outfile: h2o_java.aggregate-stats.json\n >> wrote to outfile: xalan_c-linklist.aggregate-stats.json\n >> wrote to outfile: xalan_c-dynamicarray.aggregate-stats.json\n >> wrote to outfile: xalan_java.aggregate-stats.json\n >> wrote to outfile: graphchi_c-linklist.aggregate-stats.json\n >> wrote to outfile: graphchi_c-dynamicarray.aggregate-stats.json\n >> wrote to outfile: graphchi_java.aggregate-stats.json\n >> wrote to outfile: avrora_c-linklist.aggregate-stats.json\n >> wrote to outfile: avrora_c-dynamicarray.aggregate-stats.json\n >> wrote to outfile: avrora_java.aggregate-stats.json\n"
     ]
    }
   ],
   "source": [
    "benchmarks = list(set([ fname.split('_')[0] for fname in os.listdir() ]))\n",
    "\n",
    "for bench in benchmarks:\n",
    "    for monitor_type in ['c-linklist', 'c-dynamicarray', 'java']:\n",
    "        filenames = [ f for f in os.listdir() if f.startswith(bench) and f.endswith('.stats.json')]\n",
    "        fhs = [open(f) for f in filenames]\n",
    "        data = [json.loads(fh.read()) for fh in fhs]\n",
    "        data = [d for d in data if d['metadata']['monitor_type'] == monitor_type ]\n",
    "        for fh in fhs: fh.close()\n",
    "\n",
    "        # aggregate metadata (lifetime, numsamples. save monitor_type and benchmark), memory, and persocket->{{powerdomain-energy},time}\n",
    "        aggregated = {}\n",
    "\n",
    "        aggregated['metadata'] = data[0]['metadata'] # copy over the first [metadata] block to keep common fields, over-write the aggregated fields\n",
    "        aggregated['metadata']['lifetime'] = statistics.mean([ dat['metadata']['lifetime'] for dat in data ])\n",
    "        aggregated['metadata']['numSamples'] = statistics.mean([ dat['metadata']['num_samples'] for dat in data ])\n",
    "        aggregated['metadata']['iteration'] = 'AGGREGATE'\n",
    "\n",
    "        aggregated['memory'] = {}\n",
    "        aggregated['memory']['jraplon' ] = aggregate_memory_stats([ dat['memory']['jraplon']  for dat in data ])\n",
    "        aggregated['memory']['jraploff'] = aggregate_memory_stats([ dat['memory']['jraploff'] for dat in data ])\n",
    "\n",
    "        aggregated['persocket'] = {}\n",
    "        aggregated['persocket']['time-between-samples'] = {}\n",
    "        aggregated['persocket'] = general_aggregate( [ dat['persocket'] for dat in data ] )\n",
    "\n",
    "        outfilename = aggregated['metadata']['benchmark'] + \"_\" + aggregated['metadata']['monitor_type'] + \".aggregate-stats.json\"\n",
    "        with open(outfilename,'w') as outfile: outfile.write(json.dumps(aggregated))\n",
    "        print(\" >> wrote to outfile: \" + outfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}